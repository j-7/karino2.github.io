---
title: "論文読み-タグの関連を使ってタグによる画像検索を改善する"
date: 2017-09-18 13:44:16
---

Tag-Based Image Retrieval Improved by Augmented Features and Group-Based Refinmentを読む。

あくまで我らの論文と関係ありそうな所はあるか？という視点でのメモ。

---
本件とは関係ないが、semantic gapについて一言説明がある。色とか形とかのlow levelのfeatureとhigh levelのsemantic conceptの間のギャップらしい。
---

この論文で扱うタスクは、ユーザーの撮ったタグづけされてない生の写真たちに対して、テキストのクエリーで検索する、という物。

参考文献2も同じタスクをこなしているらしい。クエリに対してweb から正と負のトレーニングデータを集めて来てSVMをトレーニングして使うだとか。

## 手法の概要

2つの方法を組み合わせているっぽい。

1. AFSVMを使ったタグrelevance推計
2. グループベースのタグrelevance refinment

### AFSVM

Augmented FeatureのSVMらしい。

Augmented Featureというのは、最初に良くあるタグを400個選び、このタグの1 vs allの分類器をトレーニングし、この分類器によるpredictのスコアを元のfeatureにconcatしてトレーニングしたSVMらしい。

ようするに、400個のポピュラーなタグの1 vs all分類器を

![](https://i.imgur.com/J5JAx0G.jpg)

と置くと（Kは400）、新たなフィーチャーは

![](https://i.imgur.com/ersYLBU.jpg)

と表せて、これと元のフィーチャーをconcatした


![](https://i.imgur.com/rY3OPZ0.jpg)

に対してトレーニングしたSVMをAFSVMと呼んでるらしい。

このjustificationはマイナーなタグというのは、もっと良く使われているタグの中に近い物がある事が多いので、それらポピュラーなタグとのsemanticな関係を学習して、検索の質を上げるとの事。

例えば「水」というあまり見かけないタグは、もっとポピュラーな「川」とか「湖」のような概念との関係を学習する事で、トレーニングデータの少ない「水」の分類器の精度を改善出来るとか。

### グループベースのタグrelevance refinment

ここで言うグループというのは、以下の定義の模様。
ユーザーの撮った写真というのは、近い時間の間に撮った写真や同じイベント（クリスマスとか）に撮った写真はsemanticallyに関連している、という仮定のもと、それらをグループとして扱うというものらしい。

グループ分け自体は既にされている、という前提っぽい？

タグのrefinmentはLaplacian regularized least square という手法でやるらしい。

こちらは我々のケースとはあまり関係無さそう。

## 雑感

タグのrelevanceを学習すると期待して読んだのだが、そこはあらわに学習する訳では無くて、内部で考慮される、くらいの話だった。

ただ我々と解こうとしている課題は似ているので、そこは参考になりそう。
