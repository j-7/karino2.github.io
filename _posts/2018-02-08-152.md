---
title: "Probabilistic Metric Spaces (Dover Books on Mathematics)を読むぞ！"
date: 2018-02-08 14:10:30
---

[という訳で](https://karino2.github.io/2018/02/08/150.html)、Probabilistic Metric Spaces (Dover Books on Mathematics)を読んでいく事にする。

<iframe style="width:120px;height:240px;" marginwidth="0" marginheight="0" scrolling="no" frameborder="0" src="https://rcm-fe.amazon-adsystem.com/e/cm?ref=qf_sp_asin_til&t=karino203-22&m=amazon&o=9&p=8&l=as1&IS1=1&detail=1&asins=0486445143&bc1=ffffff&lt1=_top&fc1=333333&lc1=0066c0&bg1=ffffff&f=ifr"> </iframe>

さっそく1.1で$$F_{pq}$$の定義が出てくる。そうそう、やっぱこういうのが足りてなかったんだよな。

### 1.2.5を追ってみる

で、1.2のTの定義は良く分からないな。なんか関数解析の最初の方で見た事ある気がするが…

で、dを決めるとmetricの定義を満たす、とあるので自分で試してみよう。

![](https://i.imgur.com/5ABPJOv.jpg)

この2つの条件と、1.1.7-1.1.10から、距離の3つの定義である1.1.1〜1.1.4を満たす事を示せば良い。

まずは1.1.1から。って微妙に書き方が分かりにくいな。
まず、dがゼロならp, qが等しい、を示す。

![](https://i.imgur.com/oBKewUg.jpg)

次にp=qならdはゼロ、を示そう。

p=qだから、1.1.8あたりを使ってみよう。

![](https://i.imgur.com/Y8HjtyK.jpg)

言えそうだね。

この手のは三角不等式以外はだいたいほとんど自明なんだが、それを確認するのは結構理解を助けるので、もう少しやってみよう。

次は1.1.2。

![](https://i.imgur.com/x4egY7L.jpg)

言えそう。逆はどうだろう？

1.1.8からあるxで1じゃなくて、その値をDと置いて1.2.5に代入すればdがDより大きい、つまりゼロじゃないと言えそうね。

対称律はどうだろう？
1.1.10からFは対称か。

すると1.2.5で同じと言えそうだな（厳密にやるとちょっと頑張る必要はありそうだが）。

そろそろ三角不等式、1.1.4に進もう。

![](https://i.imgur.com/ufTBJqu.jpg)

厳密な事を言えばxとyはdよりちょっと大きい訳だが、このちょっと大きい部分は任意の小さいイプシロンで十分なので、感覚的には成立してると言えそう。

ここまでだと1.2.3を使ってないので、そこだけいまいちピンとこない。
三角不等式の逆をやれば良さそうかな。やってみよう。

逆はdの方で三角不等式が成り立ってるとして、1.2.5を仮定して、1.2.2〜1.2.4が成り立つ任意のTに対し1.2.1を示せば良いのかね。

やってみよう。

二時間くらい頑張ったが、言えない気がしてきた。まずT(0, 0)が0とは限らない。
その他T側の条件がゆるすぎて、1.2.1を証明する事は出来ない、という結論に。

別の論文を調べてるとassociavityを仮定してるのがあるので、この辺があれば行けるのかも。

なんにせよ間違ってそうなのでやる気は失せたが、その過程でこれらの条件の理解は深まったので良しとする。

## 1.4 具体的なTの発見

どうも距離の公理と1.2.2以降を満たすTとはなんぞや、というのは、その後いろいろ研究される対象のようだな。
やはり自分には元の定義には足りてない要素があると思う。例えばいつもT(a, b)=1でも成立してしまう気がするが、それでは何も言えないはず。

が、突っ込んで考えるのはやめておく。

ただこの歴史的な話は凄く良いね。
なんで自分がこの話題に全然ついて行けなかったかが良く分かる。

さて、1.4では1.2.1を満たすTの具体的な話となるので、1.2.1を再掲しておこう。

![](https://i.imgur.com/jGcYv7d.jpg)

さて、その後t-normの話が出てくる。
定義が散らばってるので、ここでまとめておこう。

### t-norm

1.2.2、1.2.3、1.4.3、1.4.5を満たす関数をtriangular  norm（またはt-norm）と言うらしい。

![](https://i.imgur.com/d4cV9cu.jpg)

1.4.1のうち、これを満たすのはどれか、みたいな話をしてるな。考えてみよう。
1.2.3までは全部満たすので、1.4.3より先だけ考えれば十分だな。

1.4.3はMまでは満たすね。そこからは満たしてない。

1.4.5はぱっと見ただけじゃ分からないな。

![](https://i.imgur.com/3EcOmkQ.jpg)

ぱっと見は成り立ってないように見えるが、成り立つと言ってるのだから成り立つのだろう。場合分けしてみるか。

![](https://i.imgur.com/0ws5upR.jpg)

なるほど、このケースで言えそうならだいたい言えそうだな。

abcが同じなのは自明、minもa, b, cのうち一番小さい物を返す、という事は変わらない。

さて、t-normは以後良く出てくるとの事なので、ここに書いておこう。

![](https://i.imgur.com/GjnaZGl.jpg)

### Menger spaceとWald space

どちらも、$$F_{pq}$$として、1.1.7〜1.1.10を仮定している。

![](https://i.imgur.com/qqZUTvM.jpg)

そしてMenger spaceとは、あるt-norm Tと1.1.7〜1.1.10、そして1.2.1を満たす$$F_{pq}$$の張る空間。

Wald spaceは1.1.7〜1.1.10と1.3.1を満たす$$F_{pq}$$の張る空間。


![](https://i.imgur.com/azw7xn2.jpg)

そしてWald spaceは、$$\Pi$$のMenger spaceになってるとの事。

そのあとの1.5のExample で出てくるsimple spaceなどは、必要になったらちゃんと追えばいいかなぁ、という事で眺めるくらい。

distribution generated spaceはこの記述じゃ良く分からなさそうなので、必要なら後で出てくる、と期待して流す。
C-space、transformation generated spacesなどの名前が出てくる事は意識しておくが、10章への参照が多いので10章までは要らないと予想。

### 1.6 PM space

probabilistic metric spaceの定義は重要かもしれないので、ここに軽く書いておく。

1.1.7〜1.1.10と、$$F(0)=0$$と（ここまでをddfと呼ぶらしい）、以下の1.6.5を満たす$$F_{pq}$$と、

![](https://i.imgur.com/CjpdlW2.jpg)

1.6.1〜1.6.4を満たす$$\tau$$が規定する距離空間をPardmetric Metric space と呼ぶ。

![](https://i.imgur.com/lCtgewa.jpg)

ここで、$$F \leq G $$ は$$F(x) \leq G(x) $$が全部のxについて成り立ってる事を指す。

さて、ここで定義の全体を見渡してみる。Fはもともと2つの点の距離が引数以下の確率だった訳なので、気分的には距離を現していた気がしていたが、では$$\tau$$とはなんだろう？

1.6.5を三角不等式のprobabilistic metric版だとすると、やはりFが距離を表しているように見えるのだが。

これは距離の合成、みたいなのを扱っているとみなすと、+に近い物なのか？

あ、後に説明があるな。実数の距離をddfに変えて、足し算を$$\tau$$に置き換えれば良い、と。

良し、今のところなんとかついてこれてるな。

## Random metric spaces

ここは、ここまでの話と突然変わるように見える。なお、良く似たRの文字が2つあるが、微妙に形がちがくて、最初この違いに気付かなくてさっぱり意味が分からなかった。

1.7.1のDは、dの集合である。
で、Pは様々にありうるdの測度となっている。
といってもその測度がどんな物かは具体的にはこれだけじゃ分からない。

その次のStevensの定義はもう少し分かりやすいな。

E-spaceあたりから追うの辛くなってきたので、眺めるくらいで進む。
歴史的発展を扱ってる上に参照してる章が大分後半になってきたので、まぁいいだろう。

## （一章を読み終えて）Probablistic metric spaceとはどういう話か？

1章を読み終えて、なんとなくこの本で扱っている話題を理解してきたので、現時点での理解を書く。

自分は最初、確率分布同士の距離を扱っている事を期待していた。
もともとWasserstein metricやCramer metricの周辺の話題を知りたかったので。

だが、ここまで読んだ印象だと、この本ではあまり具体的なmetricは扱っていない気がする。
それよりはmetricを定義する為の下準備として$$F_{pr}(x)$$という物を定義したり、それの上での三角不等式とはなんぞや？みたいな、もう一段抽象的な所で確率分布の距離と、それの張る距離空間の性質を調べようとしているように見える。
しかも、まだこの研究は終わってないような？

直接metricの話が出てこないのはあてが外れたが、ここに出てくる数々の用語やLevy metricなどは先の挫折した本に当然のように出てきていたので、どうもこの本の内容が前提となって個々のmetricの話はある気がする。  
だから直接は役に立たなくても、ここから入門するのは正しそう。

最近のGANの話などを知る為にOptimal Transportとかでググって出てくる説明とか読んでも、明らかに足元というか基礎の部分をおさえられてない感じがする。それはこの辺の知識が無いからなんじゃないか。

一方でKantrovichの名前が一切出てこない。
という事でこの本をやっても多分必要な事まではたどり着かないようだ。
この続きをやる必要がありそう。

なんとなく今持ってるイメージだと、Optimal transportの問題は別に研究されていて、発展していった結果こちらの枠組みで議論されるようになった、という事なのだと思う。
だからこの本で扱われてる基礎を理解し、向こうの議論の発展を理解し、そして両者の発展的な統合した話を理解する必要があるんじゃないか。

この本の前提としている難しさについて。  
ここまでの感じだと、この本が前提としている知識はそんなに多くなくて、今の自分でもなんとか読める気がする。
測度論、公理的確率空間、簡単な関数解析の基礎くらいは前提にしていそうだが、そこまで習熟している事は前提にしていない気がする。

これをある程度読めば、自分に欠けている分野を自分で判断出来る所まで行けるといいなぁ。

# 2章 集合とか関数とかの定義

この章は以後で使う関数とかの定義を集めただけっぽい。
定義域とか値域の定義、とか。

さらっと流す。

### 2.1.2 quasi-inverseの定義

少し表記が頭の中だけでは整理出来なかったので、補助用の図を描いておく。

![](https://i.imgur.com/LSxxDZE.jpg)

2.1.6の定義は

1. Ran fの範囲だけでgの全値域がカバーされている
2. fのdomain側も、gの値域だけでfの値域はすべてカバー出来る
3. Ran fの範囲では、gで写像した物はfで戻る

という事を言っているな。
gのdomainが全てRan fと言っている訳では無いのに注意が必要か。

以後の$$g_3$$などの例を考えてみよう。  
$$g_3$$の値域は正の実数なので、domain側が正の実数だけで全てカバー出来ている。
で、この正の実数の範囲なら$$g_3$$で写したものは、fで戻る。

そして$$g_3$$のdomainの負の方に関しては、それが値域を「広げなければ」なんでも良い、という事だな。



----

2.2.4のあたりで休憩。
一つ一つはそんな難しくも無いのだけど、見てすぐ分かるという程この辺完璧に覚えている訳でも無いので、結構疲れる。

とは言っても細かい話はいかにも分布関数を意識してそうな物が多いので、頑張って追う。
こういう目的が分かりやすい物は頑張る気は出るやね。

----

### 2.3.2 可測関数の定義を見直す

あれ？x未満の逆像がボレル集合族、という定義だっけ？と思ったので、他の本を見直す。

まずは自分のバイブル、ルベーグ積分から確率論、

<iframe style="width:120px;height:240px;" marginwidth="0" marginheight="0" scrolling="no" frameborder="0" src="https://rcm-fe.amazon-adsystem.com/e/cm?ref=qf_sp_asin_til&t=karino203-22&m=amazon&o=9&p=8&l=as1&IS1=1&detail=1&asins=4320015622&bc1=ffffff&lt1=_top&fc1=333333&lc1=0066c0&bg1=ffffff&f=ifr"> </iframe>

を見る。

ついでにボレル集合体は、全ての開集合を含む「最小の」シグマ集合体（p18）という定義なのを確認。

可測関数の定義はp32にあって、ほとんど本書と同じ内容だ。

あれ？そうだっけ？と次のページを見ると、この定義は、ボレル集合体の任意の逆像がボレル集合体に属す、という事と等価だと書いてある。（命題2.1 の5）。

そして最近見た以下の本

<iframe style="width:120px;height:240px;" marginwidth="0" marginheight="0" scrolling="no" frameborder="0" src="https://rcm-fe.amazon-adsystem.com/e/cm?ref=qf_sp_asin_til&t=karino203-22&m=amazon&o=9&p=8&l=as1&IS1=1&detail=1&asins=0387983074&bc1=ffffff&lt1=_top&fc1=333333&lc1=0066c0&bg1=ffffff&f=ifr"> </iframe>

でも確認しておくと、p67の2.3の冒頭で、この等価な方の置き換えの言葉で書いてある。

こちらの方が感覚的に分かりやすいので、むしろこちらを覚えて、それと等価な条件としてそれ以外の物も覚えるようにしよう。

このIntroductoryの本で感覚的な定義を見た後に本書などの細かい話を見ていくと凄い理解が深まるな。
以前は各定義を追うだけで精一杯だったが、今回は大分ルベーグ積分周辺の定義や定理の関係が分かってきたヽ(´ー｀)ノ

定義2.3.2の下に、しれっと「閉区間上で定義されたnondecreasingな関数はボレル可測」と書いてあるが、そんな明らかだろうか？

nondecreasingかつ閉区間なのだから、有界なのはいい。
で、ジャンプしかありえないのだから、それは感覚的には有限個の開区間か閉区間または片方ずつの区間に分割されそうか。
で、この区間の定義域はジャンプの点を元にした開区間とか閉区間になるか。

開区間も閉区間もその和やintersectもボレル集合体だから、可測になりそうだな。

### dPによる積分が良く分からない

2.3.5の後に、$$ \int _A f dP $$というのが出てくる。
このdPによる積分が何なのか思い出せないので、ルベーグ積分周辺の話を復習しよう…

まず、Introductory Functional Analysisのp63を見ると、yつまり値域の方の開集合に対し、その逆像がシグマ集合族に属すので、その時のfの値にこのシグマ集合族をPで測った値を掛けて足し合わせるのがルベーグ積分だ。  
厳密には可測な関数は段々の定義関数の極限で近似出来るという定理があるので、これを用いる。

さて、ルベーグ積分から確率論、のp117を見ると、期待値の定義が

$$ E(X) = \int _{\Omega} X(\omega)d P(\omega)$$

というのが出てくる。オメガを取り払うと同じ式かな？という事でこの式の意味する所を考えよう。

もともとルベーグ積分は、測度をmとすると、$$\int f m(dx) $$ と書いていた。
なんでdPになってるのだろう？

と思ったが、この本の2.3.10より後を見ると、割とP-measureによるたんなるルベーグ積分になってるな。
じゃあそういうもんだと思っておくか。

### Lebesgue-Stieltjes F-measure

しれっと定義が2.3.9あたりで出てくるが、その後2.3.13の後に略記の話が出てくるので、ここにまとめておく。

ある閉区間[a, d]の上に定義された、非減少関数Fで、F(a)=0, F(d)=1となるFがあった時に、大雑把には

$$ P_F [b, c] = F(c) - F(b) $$

を、ジャンプまで含めてちゃんと定義した測度が考えられる（2.3.9）。
なお、シグマ集合族はこの場合ボレル集合族となる。

さらに、

$$ \int _A f d P_F  $$は、$$ \int _A f d F  $$ と略記する。

## 3章 metricとかの話

3章は集積点だとかの集合的な用語の定義とmetricの定義などが並ぶ。

ぶわーっと出てくるので初見では辛いだろうが、この前関数解析の入門動画を見てた時にこの辺は一通りやったので、まだ結構覚えている。

### weak metric transformとmetric transform

Def. 3.2.1のあたりで、いろいろ定義が一気に出てきて追うのがつらくなってきたので、ここにメモを書く。

ある距離空間から別の距離空間に移す変換についての話。

1の側にmetricが定義されてるとして、
fがweak metric transformとは、ある一対一関数の$$\phi$$ があった時に、

![](https://i.imgur.com/G8PZivc.jpg)

として定義した$$d_2$$がmetricとなる事を言う。

さらに順序が保存される（3.2.3）時は、このfをmetric transformと呼ぶ。

### 3.4から先が全然分からない

3.4の Minkowski Metricsが全然分からない

なんか筆記体っぽいRの定義が理解出来ず、その結果あとの記述が何も分からない。
indicatrixとは何かも分かんない。

3.4.3はL-pノルムだよな。

3.4.1は全然分からない。
仕方無いので分からないとここに記して前に進む。

3.5からは近傍系の話？第一可算公理とかの話でますます分からない。うげぇ、これは自分には無理かなぁ。

kuratowskiって名前どっかでも見た事あるのでこの辺理解したかったが、これは位相空間論の勉強が要るな。

そろそろ位相空間論を本腰を入れてやる時がきているのかもしれないが、もう少し様子を見たいので、まずは先に進んでみよう。

# 4章、Distribution Functions

三章の後半が位相空間論レベルが低すぎて全然ついていけなかったが、切り替えていこ。

4章はついにDistribution Functionで確率っぽい話になるし、この辺が良く分からないせいでいろいろ理解出来てない経験はしているので、モチベーションは高め。

### $$F_X(x)$$の定義 

良く見かける気がするので、ここにまとめておく。

R上で定義される、nondecreasingで$$F(- \infty)=0, F(\infty)=1$$な関数を、distribution functionと言う。

$$ -\infty, \infty $$で左側連続なdistribution functionを$$ \Delta $$と呼ぶ。

Xが確率空間$$ (\Omega, F, P) $$上の確率変数の時、分布関数$$F_X$$を以下で定義する。

$$F_X(- \infty)=0, F_X(\infty)=1$$  
$$F_X(x)= P\{ \omega\  \in\  \Omega | X(\omega) < x\} $$ ... 4.1.1

また、たまに$$F_X $$ は $$df(X)$$ と書かれる事もある。



### 4.2は誤植が多い…

Lenma 4.2.2は開幕t>0で、$$J_t$$の誤植だよなぁ、たぶん。

Theorem 4.2.5の$$c_m$$は、
$$ c_{m-1} < c_m < c_{m-1} + h < c_{m} + h $$
か？自信無いが。

## 4.4 Quasi Inverse

後で出てくるので簡単にまとめておく。

fが[a, b]でnondecreasingとする。
yは[f(a), f(b)]上の点とする。

この時、4.4の冒頭の説明について。  
逆写像が閉区間うんぬんは、ようするに水平な区間の場合の事を言ってる。
水平じゃなければ逆像は点となる。

次に$$ f^{-1}(y) $$が存在しない時を考える。

これが存在しない、というのは、ちょうどジャンプしてる間の点という事になる。
supだinfだ書いてあるのは、ようするにこれがジャンプしている点でyがその間にある点だ、という意味に他ならない。

### 4.4.1 Quasi-Inverseの定義

感覚的な意味を確認しておこう。

まずiは両端で逆写像になっている、と言っている。

次にii。yがRan fというのは、ようするに何かしらのxの像となっている点という事だ。
だからこの元となっているxがあるので、この場合は水平じゃなければ逆写像となっている、という事を言っている。
水平の場合はこの範囲のどこか、という事。

iiiはyがRan fに無い時、つまりジャンプの間のyの時。
この場合は$$f^{*}(y)$$がジャンプしているxとなっている、という事を言っている。

つまりQuasi-Inverseとは、

1. 水平な所ならそのxのどこか
2. ジャンプしている間ならジャンプしている点
3. 1でも2でも無ければ逆像

という事。

# 5章 Associativity

各章、最後の方は応用的な話とかOpen Problemとかになっていくので、各章を7割くらい真面目にやったら、トピックだけ眺めて次に進むのが良い気がしてきたので、4章の後半は眺めるだけにして5章に進む。

そもそもこの本は最終目標じゃないので、次に進む為の道具を集められたら役目は終わるのだ。
どこまでやる必要があるか分からないが、要らない、と思う所まで進めてみよう。

### 5.1.1周辺のメモ

vertical sectionとhorizontal sectionが出てきたので、復習しておく。
これこ定義は2.4.2にある。

SxS上で定義されたbinary operationであるTにおいて、任意のSの元aについて、aに置けるTのvertica sectionとは、

![](https://i.imgur.com/EIgtEP3.jpg)

と定義される関数 $$ v_a(x) $$ の事である。

さて、これを踏まえて5.1.1は成り立つか？

![](https://i.imgur.com/iO5uX7I.jpg)

という事なので成り立ちそうな気はするね。証明はまぁいいだろう。

### 5.2.1の定義周辺（半群の生成）

半群: 逆元の無い群。定義は5.1にある。具体的にはS上のbinary operationであるTが、associativityを満たしている時、(S, T)を半群と呼ぶ。

2.1.2にQuasi-Inverseの一般的な定義がある。gがfのquasi-inverseなのを、$$g[Q]f$$と書く。

さて、5.2.1のうち、ivとvがややこしいので、iからiiiまでの状況をまず図解する。

![](https://i.imgur.com/z7cvJtJ.jpg)

さて、ivはこの$$T_1$$の先が必ずRan gの輪の中にある、という意味だ。これは分かりやすい。

vが良く分からん。
あとの証明と比較して考えると、ちょっと分かってきた。これはaは一つなのか。

$$T_1$$の先でRan gの輪から出てる所をfで移すと、必ず同じ点aに移るという事かな？
で、しかもこのaに行けるのは

1. 輪の外の$$T_1$$の像から
2. $$f(u) = a$$か$$f(v) = a$$となるuかvを使った$$T_1(u, v)$$からか

のどちらか、という事か。

5.2.1はようするに、gで移した先で$$T_1$$を適用しfで戻す、と言っている。
これでもassociativityが保たれる為の十分条件として、ivかvが要る、と言っている。

ivの場合は簡単で、それにvという拡張も加えられる、という事かね。vははみ出た部分については結構きつい条件なので、見た目ほどすごい定理でも無いが。

vというこんなややこしい条件をつけてるのは、応用的な意味があるのだろうな。

### 5.2.2 generatedの定義

重要そうなので書きとめておく。

$$(S, T_1)$$が半群で、f, g が以下の3つの条件と、4か5の条件を満たす関数の時、

1. Ran gはSのサブセット
2. Ran g内の任意のu, vについて、$$T_1(u, v) $$が Dom fの中
3. f[Q]g
4. Dom g上の任意のx, yに対して、$$T_1(g(x), g(y))$$がRan gの中、または
5. Ran fの中にaで、($$f(u)=a$$か$$f(v)=a$$か(u, vがRan gだが$$T_1(u, v)$$がRan gじゃない))のどれかが成り立つ時はいつでも $$a = T_1(u, v)$$となる物が存在する

時に、Dom g上のbinary operator で以下のようなTを定義すると、


![](https://i.imgur.com/DyOY86U.jpg)

(Dom  g, T)は半群となる。（Theorem 5.2.1）

この時、Tは$$T_1$$からペア(f, g)によってgeneratedされた、と言う。
