---
title: "Probabilistic Metric Spaces (Dover Books on Mathematics)を読むぞ！"
date: 2018-02-08 14:10:30
---

[という訳で](https://karino2.github.io/2018/02/08/150.html)、Probabilistic Metric Spaces (Dover Books on Mathematics)を読んでいく事にする。

<iframe style="width:120px;height:240px;" marginwidth="0" marginheight="0" scrolling="no" frameborder="0" src="https://rcm-fe.amazon-adsystem.com/e/cm?ref=qf_sp_asin_til&t=karino203-22&m=amazon&o=9&p=8&l=as1&IS1=1&detail=1&asins=0486445143&bc1=ffffff&lt1=_top&fc1=333333&lc1=0066c0&bg1=ffffff&f=ifr"> </iframe>

さっそく1.1で$$F_{pq}$$の定義が出てくる。そうそう、やっぱこういうのが足りてなかったんだよな。

### 1.2.5を追ってみる

で、1.2のTの定義は良く分からないな。なんか関数解析の最初の方で見た事ある気がするが…

で、dを決めるとmetricの定義を満たす、とあるので自分で試してみよう。

![](https://i.imgur.com/5ABPJOv.jpg)

この2つの条件と、1.1.7-1.1.10から、距離の3つの定義である1.1.1〜1.1.4を満たす事を示せば良い。

まずは1.1.1から。って微妙に書き方が分かりにくいな。
まず、dがゼロならp, qが等しい、を示す。

![](https://i.imgur.com/oBKewUg.jpg)

次にp=qならdはゼロ、を示そう。

p=qだから、1.1.8あたりを使ってみよう。

![](https://i.imgur.com/Y8HjtyK.jpg)

言えそうだね。

この手のは三角不等式以外はだいたいほとんど自明なんだが、それを確認するのは結構理解を助けるので、もう少しやってみよう。

次は1.1.2。

![](https://i.imgur.com/x4egY7L.jpg)

言えそう。逆はどうだろう？

1.1.8からあるxで1じゃなくて、その値をDと置いて1.2.5に代入すればdがDより大きい、つまりゼロじゃないと言えそうね。

対称律はどうだろう？
1.1.10からFは対称か。

すると1.2.5で同じと言えそうだな（厳密にやるとちょっと頑張る必要はありそうだが）。

そろそろ三角不等式、1.1.4に進もう。

![](https://i.imgur.com/ufTBJqu.jpg)

厳密な事を言えばxとyはdよりちょっと大きい訳だが、このちょっと大きい部分は任意の小さいイプシロンで十分なので、感覚的には成立してると言えそう。

ここまでだと1.2.3を使ってないので、そこだけいまいちピンとこない。
三角不等式の逆をやれば良さそうかな。やってみよう。

逆はdの方で三角不等式が成り立ってるとして、1.2.5を仮定して、1.2.2〜1.2.4が成り立つ任意のTに対し1.2.1を示せば良いのかね。

やってみよう。

二時間くらい頑張ったが、言えない気がしてきた。まずT(0, 0)が0とは限らない。
その他T側の条件がゆるすぎて、1.2.1を証明する事は出来ない、という結論に。

別の論文を調べてるとassociavityを仮定してるのがあるので、この辺があれば行けるのかも。

なんにせよ間違ってそうなのでやる気は失せたが、その過程でこれらの条件の理解は深まったので良しとする。

## 1.4 具体的なTの発見

どうも距離の公理と1.2.2以降を満たすTとはなんぞや、というのは、その後いろいろ研究される対象のようだな。
やはり自分には元の定義には足りてない要素があると思う。例えばいつもT(a, b)=1でも成立してしまう気がするが、それでは何も言えないはず。

が、突っ込んで考えるのはやめておく。

ただこの歴史的な話は凄く良いね。
なんで自分がこの話題に全然ついて行けなかったかが良く分かる。

さて、1.4では1.2.1を満たすTの具体的な話となるので、1.2.1を再掲しておこう。

![](https://i.imgur.com/jGcYv7d.jpg)

さて、その後t-normの話が出てくる。
定義が散らばってるので、ここでまとめておこう。

### t-norm

1.2.2、1.2.3、1.4.3、1.4.5を満たす関数をtriangular  norm（またはt-norm）と言うらしい。

![](https://i.imgur.com/d4cV9cu.jpg)

1.4.1のうち、これを満たすのはどれか、みたいな話をしてるな。考えてみよう。
1.2.3までは全部満たすので、1.4.3より先だけ考えれば十分だな。

1.4.3はMまでは満たすね。そこからは満たしてない。

1.4.5はぱっと見ただけじゃ分からないな。

![](https://i.imgur.com/3EcOmkQ.jpg)

ぱっと見は成り立ってないように見えるが、成り立つと言ってるのだから成り立つのだろう。場合分けしてみるか。

![](https://i.imgur.com/0ws5upR.jpg)

なるほど、このケースで言えそうならだいたい言えそうだな。

abcが同じなのは自明、minもa, b, cのうち一番小さい物を返す、という事は変わらない。

さて、t-normは以後良く出てくるとの事なので、ここに書いておこう。

![](https://i.imgur.com/GjnaZGl.jpg)

### Menger spaceとWald space

どちらも、$$F_{pq}$$として、1.1.7〜1.1.10を仮定している。

![](https://i.imgur.com/qqZUTvM.jpg)

そしてMenger spaceとは、あるt-norm Tと1.1.7〜1.1.10、そして1.2.1を満たす$$F_{pq}$$の張る空間。

Wald spaceは1.1.7〜1.1.10と1.3.1を満たす$$F_{pq}$$の張る空間。


![](https://i.imgur.com/azw7xn2.jpg)

そしてWald spaceは、$$\Pi$$のMenger spaceになってるとの事。

そのあとの1.5のExample で出てくるsimple spaceなどは、必要になったらちゃんと追えばいいかなぁ、という事で眺めるくらい。

distribution generated spaceはこの記述じゃ良く分からなさそうなので、必要なら後で出てくる、と期待して流す。
C-space、transformation generated spacesなどの名前が出てくる事は意識しておくが、10章への参照が多いので10章までは要らないと予想。

### 1.6 PM space

probabilistic metric spaceの定義は重要かもしれないので、ここに軽く書いておく。

1.1.7〜1.1.10と、$$F(0)=0$$と（ここまでをddfと呼ぶらしい）、以下の1.6.5を満たす$$F_{pq}$$と、

![](https://i.imgur.com/CjpdlW2.jpg)

1.6.1〜1.6.4を満たす$$\tau$$が規定する距離空間をPardmetric Metric space と呼ぶ。

![](https://i.imgur.com/lCtgewa.jpg)

ここで、$$F \leq G $$ は$$F(x) \leq G(x) $$が全部のxについて成り立ってる事を指す。

さて、ここで定義の全体を見渡してみる。Fはもともと2つの点の距離が引数以下の確率だった訳なので、気分的には距離を現していた気がしていたが、では$$\tau$$とはなんだろう？

1.6.5を三角不等式のprobabilistic metric版だとすると、やはりFが距離を表しているように見えるのだが。

これは距離の合成、みたいなのを扱っているとみなすと、+に近い物なのか？

あ、後に説明があるな。実数の距離をddfに変えて、足し算を$$\tau$$に置き換えれば良い、と。

良し、今のところなんとかついてこれてるな。

## Random metric spaces

ここは、ここまでの話と突然変わるように見える。なお、良く似たRの文字が2つあるが、微妙に形がちがくて、最初この違いに気付かなくてさっぱり意味が分からなかった。

1.7.1のDは、dの集合である。
で、Pは様々にありうるdの測度となっている。
といってもその測度がどんな物かは具体的にはこれだけじゃ分からない。

その次のStevensの定義はもう少し分かりやすいな。

E-spaceあたりから追うの辛くなってきたので、眺めるくらいで進む。
歴史的発展を扱ってる上に参照してる章が大分後半になってきたので、まぁいいだろう。

## （一章を読み終えて）Probablistic metric spaceとはどういう話か？

1章を読み終えて、なんとなくこの本で扱っている話題を理解してきたので、現時点での理解を書く。

自分は最初、確率分布同士の距離を扱っている事を期待していた。
もともとWasserstein metricやCramer metricの周辺の話題を知りたかったので。

だが、ここまで読んだ印象だと、この本ではあまり具体的なmetricは扱っていない気がする。
それよりはmetricを定義する為の下準備として$$F_{pr}(x)$$という物を定義したり、それの上での三角不等式とはなんぞや？みたいな、もう一段抽象的な所で確率分布の距離と、それの張る距離空間の性質を調べようとしているように見える。
しかも、まだこの研究は終わってないような？

直接metricの話が出てこないのはあてが外れたが、ここに出てくる数々の用語やLevy metricなどは先の挫折した本に当然のように出てきていたので、どうもこの本の内容が前提となって個々のmetricの話はある気がする。  
だから直接は役に立たなくても、ここから入門するのは正しそう。

最近のGANの話などを知る為にOptimal Transportとかでググって出てくる説明とか読んでも、明らかに足元というか基礎の部分をおさえられてない感じがする。それはこの辺の知識が無いからなんじゃないか。

一方でKantrovichの名前が一切出てこない。
という事でこの本をやっても多分必要な事まではたどり着かないようだ。
この続きをやる必要がありそう。

なんとなく今持ってるイメージだと、Optimal transportの問題は別に研究されていて、発展していった結果こちらの枠組みで議論されるようになった、という事なのだと思う。
だからこの本で扱われてる基礎を理解し、向こうの議論の発展を理解し、そして両者の発展的な統合した話を理解する必要があるんじゃないか。

この本の前提としている難しさについて。  
ここまでの感じだと、この本が前提としている知識はそんなに多くなくて、今の自分でもなんとか読める気がする。
測度論、公理的確率空間、簡単な関数解析の基礎くらいは前提にしていそうだが、そこまで習熟している事は前提にしていない気がする。

これをある程度読めば、自分に欠けている分野を自分で判断出来る所まで行けるといいなぁ。

# 2章 集合とか関数とかの定義

この章は以後で使う関数とかの定義を集めただけっぽい。
定義域とか値域の定義、とか。

さらっと流す。

### 2.1.2 quasi-inverseの定義

少し表記が頭の中だけでは整理出来なかったので、補助用の図を描いておく。

![](https://i.imgur.com/LSxxDZE.jpg)

2.1.6の定義は

1. Ran fの範囲だけでgの全値域がカバーされている
2. fのdomain側も、gの値域だけでfの値域はすべてカバー出来る
3. Ran fの範囲では、gで写像した物はfで戻る

という事を言っているな。
gのdomainが全てRan fと言っている訳では無いのに注意が必要か。

以後の$$g_3$$などの例を考えてみよう。  
$$g_3$$の値域は正の実数なので、domain側が正の実数だけで全てカバー出来ている。
で、この正の実数の範囲なら$$g_3$$で写したものは、fで戻る。

そして$$g_3$$のdomainの負の方に関しては、それが値域を「広げなければ」なんでも良い、という事だな。



----

2.2.4のあたりで休憩。
一つ一つはそんな難しくも無いのだけど、見てすぐ分かるという程この辺完璧に覚えている訳でも無いので、結構疲れる。

とは言っても細かい話はいかにも分布関数を意識してそうな物が多いので、頑張って追う。
こういう目的が分かりやすい物は頑張る気は出るやね。

----

### 2.3.2 可測関数の定義を見直す

あれ？x未満の逆像がボレル集合族、という定義だっけ？と思ったので、他の本を見直す。

まずは自分のバイブル、ルベーグ積分から確率論、

<iframe style="width:120px;height:240px;" marginwidth="0" marginheight="0" scrolling="no" frameborder="0" src="https://rcm-fe.amazon-adsystem.com/e/cm?ref=qf_sp_asin_til&t=karino203-22&m=amazon&o=9&p=8&l=as1&IS1=1&detail=1&asins=4320015622&bc1=ffffff&lt1=_top&fc1=333333&lc1=0066c0&bg1=ffffff&f=ifr"> </iframe>

を見る。

ついでにボレル集合体は、全ての開集合を含む「最小の」シグマ集合体（p18）という定義なのを確認。

可測関数の定義はp32にあって、ほとんど本書と同じ内容だ。

あれ？そうだっけ？と次のページを見ると、この定義は、ボレル集合体の任意の逆像がボレル集合体に属す、という事と等価だと書いてある。（命題2.1 の5）。

そして最近見た以下の本

<iframe style="width:120px;height:240px;" marginwidth="0" marginheight="0" scrolling="no" frameborder="0" src="https://rcm-fe.amazon-adsystem.com/e/cm?ref=qf_sp_asin_til&t=karino203-22&m=amazon&o=9&p=8&l=as1&IS1=1&detail=1&asins=0387983074&bc1=ffffff&lt1=_top&fc1=333333&lc1=0066c0&bg1=ffffff&f=ifr"> </iframe>

でも確認しておくと、p67の2.3の冒頭で、この等価な方の置き換えの言葉で書いてある。

こちらの方が感覚的に分かりやすいので、むしろこちらを覚えて、それと等価な条件としてそれ以外の物も覚えるようにしよう。

このIntroductoryの本で感覚的な定義を見た後に本書などの細かい話を見ていくと凄い理解が深まるな。
以前は各定義を追うだけで精一杯だったが、今回は大分ルベーグ積分周辺の定義や定理の関係が分かってきたヽ(´ー｀)ノ

定義2.3.2の下に、しれっと「閉区間上で定義されたnondecreasingな関数はボレル可測」と書いてあるが、そんな明らかだろうか？

nondecreasingかつ閉区間なのだから、有界なのはいい。
で、ジャンプしかありえないのだから、それは感覚的には有限個の開区間か閉区間または片方ずつの区間に分割されそうか。
で、この区間の定義域はジャンプの点を元にした開区間とか閉区間になるか。

開区間も閉区間もその和やintersectもボレル集合体だから、可測になりそうだな。

### dPによる積分が良く分からない

2.3.5の後に、$$ \int _A f dP $$というのが出てくる。
このdPによる積分が何なのか思い出せないので、ルベーグ積分周辺の話を復習しよう…

まず、Introductory Functional Analysisのp63を見ると、yつまり値域の方の開集合に対し、その逆像がシグマ集合族に属すので、その時のfの値にこのシグマ集合族をPで測った値を掛けて足し合わせるのがルベーグ積分だ。  
厳密には可測な関数は段々の定義関数の極限で近似出来るという定理があるので、これを用いる。

さて、ルベーグ積分から確率論、のp117を見ると、期待値の定義が

$$ E(X) = \int _{\Omega} X(\omega)d P(\omega)$$

というのが出てくる。オメガを取り払うと同じ式かな？という事でこの式の意味する所を考えよう。

もともとルベーグ積分は、測度をmとすると、$$\int f m(dx) $$ と書いていた。
なんでdPになってるのだろう？

と思ったが、この本の2.3.10より後を見ると、割とP-measureによるたんなるルベーグ積分になってるな。
じゃあそういうもんだと思っておくか。

### Lebesgue-Stieltjes F-measure

しれっと定義が2.3.9あたりで出てくるが、その後2.3.13の後に略記の話が出てくるので、ここにまとめておく。

ある閉区間[a, d]の上に定義された、非減少関数Fで、F(a)=0, F(d)=1となるFがあった時に、大雑把には

$$ P_F [b, c] = F(c) - F(b) $$

を、ジャンプまで含めてちゃんと定義した測度が考えられる（2.3.9）。
なお、シグマ集合族はこの場合ボレル集合族となる。

さらに、

$$ \int _A f d P_F  $$は、$$ \int _A f d F  $$ と略記する。

## 3章 metricとかの話

3章は集積点だとかの集合的な用語の定義とmetricの定義などが並ぶ。

ぶわーっと出てくるので初見では辛いだろうが、この前関数解析の入門動画を見てた時にこの辺は一通りやったので、まだ結構覚えている。

### weak metric transformとmetric transform

Def. 3.2.1のあたりで、いろいろ定義が一気に出てきて追うのがつらくなってきたので、ここにメモを書く。

ある距離空間から別の距離空間に移す変換についての話。

1の側にmetricが定義されてるとして、
fがweak metric transformとは、ある一対一関数の$$\phi$$ があった時に、

![](https://i.imgur.com/G8PZivc.jpg)

として定義した$$d_2$$がmetricとなる事を言う。

さらに順序が保存される（3.2.3）時は、このfをmetric transformと呼ぶ。

### 3.4から先が全然分からない

3.4の Minkowski Metricsが全然分からない

なんか筆記体っぽいRの定義が理解出来ず、その結果あとの記述が何も分からない。
indicatrixとは何かも分かんない。

3.4.3はL-pノルムだよな。

3.4.1は全然分からない。
仕方無いので分からないとここに記して前に進む。

3.5からは近傍系の話？第一可算公理とかの話でますます分からない。うげぇ、これは自分には無理かなぁ。

kuratowskiって名前どっかでも見た事あるのでこの辺理解したかったが、これは位相空間論の勉強が要るな。

そろそろ位相空間論を本腰を入れてやる時がきているのかもしれないが、もう少し様子を見たいので、まずは先に進んでみよう。

# 4章、Distribution Functions

三章の後半が位相空間論レベルが低すぎて全然ついていけなかったが、切り替えていこ。

4章はついにDistribution Functionで確率っぽい話になるし、この辺が良く分からないせいでいろいろ理解出来てない経験はしているので、モチベーションは高め。

### $$F_X(x)$$の定義 

良く見かける気がするので、ここにまとめておく。

R上で定義される、nondecreasingで$$F(- \infty)=0, F(\infty)=1$$な関数を、distribution functionと言う。

$$ -\infty, \infty $$で左側連続なdistribution functionを$$ \Delta $$と呼ぶ。

Xが確率空間$$ (\Omega, F, P) $$上の確率変数の時、分布関数$$F_X$$を以下で定義する。

$$F_X(- \infty)=0, F_X(\infty)=1$$  
$$F_X(x)= P\{ \omega\  \in\  \Omega | X(\omega) < x\} $$ ... 4.1.1

また、たまに$$F_X $$ は $$df(X)$$ と書かれる事もある。



### 4.2は誤植が多い…

Lenma 4.2.2は開幕t>0で、$$J_t$$の誤植だよなぁ、たぶん。

Theorem 4.2.5の$$c_m$$は、
$$ c_{m-1} < c_m < c_{m-1} + h < c_{m} + h $$
か？自信無いが。

## 4.4 Quasi Inverse

後で出てくるので簡単にまとめておく。

fが[a, b]でnondecreasingとする。
yは[f(a), f(b)]上の点とする。

この時、4.4の冒頭の説明について。  
逆写像が閉区間うんぬんは、ようするに水平な区間の場合の事を言ってる。
水平じゃなければ逆像は点となる。

次に$$ f^{-1}(y) $$が存在しない時を考える。

これが存在しない、というのは、ちょうどジャンプしてる間の点という事になる。
supだinfだ書いてあるのは、ようするにこれがジャンプしている点でyがその間にある点だ、という意味に他ならない。

### 4.4.1 Quasi-Inverseの定義

感覚的な意味を確認しておこう。

まずiは両端で逆写像になっている、と言っている。

次にii。yがRan fというのは、ようするに何かしらのxの像となっている点という事だ。
だからこの元となっているxがあるので、この場合は水平じゃなければ逆写像となっている、という事を言っている。
水平の場合はこの範囲のどこか、という事。

iiiはyがRan fに無い時、つまりジャンプの間のyの時。
この場合は$$f^{*}(y)$$がジャンプしているxとなっている、という事を言っている。

つまりQuasi-Inverseとは、

1. 水平な所ならそのxのどこか
2. ジャンプしている間ならジャンプしている点
3. 1でも2でも無ければ逆像

という事。

# 5章 Associativity

各章、最後の方は応用的な話とかOpen Problemとかになっていくので、各章を7割くらい真面目にやったら、トピックだけ眺めて次に進むのが良い気がしてきたので、4章の後半は眺めるだけにして5章に進む。

そもそもこの本は最終目標じゃないので、次に進む為の道具を集められたら役目は終わるのだ。
どこまでやる必要があるか分からないが、要らない、と思う所まで進めてみよう。

### 5.1.1周辺のメモ

vertical sectionとhorizontal sectionが出てきたので、復習しておく。
これこ定義は2.4.2にある。

SxS上で定義されたbinary operationであるTにおいて、任意のSの元aについて、aに置けるTのvertica sectionとは、

![](https://i.imgur.com/EIgtEP3.jpg)

と定義される関数 $$ v_a(x) $$ の事である。

さて、これを踏まえて5.1.1は成り立つか？

![](https://i.imgur.com/iO5uX7I.jpg)

という事なので成り立ちそうな気はするね。証明はまぁいいだろう。

### 5.2.1の定義周辺（半群の生成）

半群: 逆元の無い群。定義は5.1にある。具体的にはS上のbinary operationであるTが、associativityを満たしている時、(S, T)を半群と呼ぶ。

2.1.2にQuasi-Inverseの一般的な定義がある。gがfのquasi-inverseなのを、$$g[Q]f$$と書く。

さて、5.2.1のうち、ivとvがややこしいので、iからiiiまでの状況をまず図解する。

![](https://i.imgur.com/z7cvJtJ.jpg)

さて、ivはこの$$T_1$$の先が必ずRan gの輪の中にある、という意味だ。これは分かりやすい。

vが良く分からん。
あとの証明と比較して考えると、ちょっと分かってきた。これはaは一つなのか。

$$T_1$$の先でRan gの輪から出てる所をfで移すと、必ず同じ点aに移るという事かな？
で、しかもこのaに行けるのは

1. 輪の外の$$T_1$$の像から
2. $$f(u) = a$$か$$f(v) = a$$となるuかvを使った$$T_1(u, v)$$からか

のどちらか、という事か。

5.2.1はようするに、gで移した先で$$T_1$$を適用しfで戻す、と言っている。
これでもassociativityが保たれる為の十分条件として、ivかvが要る、と言っている。

ivの場合は簡単で、それにvという拡張も加えられる、という事かね。vははみ出た部分については結構きつい条件なので、見た目ほどすごい定理でも無いが。

vというこんなややこしい条件をつけてるのは、応用的な意味があるのだろうな。

### 5.2.2 generatedの定義

重要そうなので書きとめておく。

$$(S, T_1)$$が半群で、f, g が以下の3つの条件と、4か5の条件を満たす関数の時、

1. Ran gはSのサブセット
2. Ran g内の任意のu, vについて、$$T_1(u, v) $$が Dom fの中
3. f[Q]g
4. Dom g上の任意のx, yに対して、$$T_1(g(x), g(y))$$がRan gの中、または
5. Ran fの中にaで、($$f(u)=a$$か$$f(v)=a$$か(u, vがRan gだが$$T_1(u, v)$$がRan gじゃない))のどれかが成り立つ時はいつでも $$a = T_1(u, v)$$となる物が存在する

時に、Dom g上のbinary operator で以下のようなTを定義すると、


![](https://i.imgur.com/DyOY86U.jpg)

(Dom  g, T)は半群となる。（Theorem 5.2.1）

この時、Tは$$T_1$$からペア(f, g)によってgenerateされた、と言う。

ふむ。

### ordinal sum

5.2のもう一つのトピックとの事なので軽く見ておく。だが5.2.4の定義がまた分かりにくい。具体例があると良いのだが…

二番目の条件から、一番目の $$S_{\beta} $$ はnull element一つ、という事だよなぁ。
と言っても要素が一つならnullであると同時にidentityだと思うが。

だが大小関係はいまいちよく意味が分からない。あくまで交差の部分だけの条件に見える。nullとidentityの違いがあるが、それの意味する所はいまいち分からないなぁ。

まぁいい。以上を踏まえてordinal sumの定義、5.2.5を見ると、

![](https://i.imgur.com/GuYEFY6.jpg)

Tは所属する$$S_ {\alpha} $$ の $$\alpha$$が小さい方を返すオペレータに見える。同じ時は$$T_ {\alpha} $$にfall backするような。

## 5.3 閉区間上のAssociative Functions

5.3.1と5.3.2が基礎となる条件で、それにいろいろ組み合わせるのだが、ややこしい。
まずこれを書くか。


![](https://i.imgur.com/OkRWOqW.png)

5.3.1が順序を保存する、という事で、5.3.2は右端では単位元になってる、という事だな。

これだけで減少していく二項演算な事が決まるらしい。5.3.5はまさにその表現だな。

さらに以下の2つを足したものがシータの定義らしい。

![](https://i.imgur.com/e6bzFHD.png)

5.3.7はLemma 5.3.7の所で使ってるが、その心はなんなのか。

次のArchimedianを考えると少し分かる。デルタを適用すると少し小さくなる訳だが、これを大きい値から延々と繰り返していった時に、どんどんxに近づいていく訳だな。

で、ここでジャンプがあると、いつまでたっても右側極限ではこのジャンプまでたどり着かないから、アルキメデス性が満たせない場合があるのか。

5.3.8はxに収束するようなケースを扱う時に、ちょっとずれても大きな変化が無いって事だよな。まぁ分かる。

### 5.3.6 Archimedean

あとの方で出てきてたArchimedeanの定義が出てきているので確認しておこう。

5.3.1と5.3.2を満たすTで、任意のx, yで、xを死ぬほど（Tで）指数乗すれば、やがてyより小さくなる、という話。

5.3.1と5.3.2を満たすとデルタは小さくなるので、aまでたどり着けるなら自明だな。

Wikipediaとか見ると、2つの実数x, yがあって、xを足しまくるとやがてyより大きくなる、と言っている。大小は逆だが同じ事だろう。

### 5.3.8に見る、ordinal sumの具体例

5.3.8でordinal sumの所の良く分からない定義の具体例が分かる。

nondecreasingな物を対象にしていると、有限個の互いに点しか共有しない閉区間や開区間に分割出来て、共有部分は下の区間から見るとeなのでidentity、上の区間から見るとaなので、null要素となる（5.3.3参照）。

という事で、ordinal sumの交差の条件は、感覚的にはこのジャンプがある所での閉区間の分割に相当している訳だな。

ではordinal sumで定義されるTは何か、というと、区間内は$$T_{\alpha}$$を使って、別区間同士の時は小さい方の区間を返すbinary operationという事になる。

aがnullになる事を思えば、それを越えたさらに小さい物がnullになるのは自然に思う。
そういう点では左の端点を延長した感じになってるんだな。

## 5.4 ArchimedeanのRepresentation

追加の条件を2つほどつけると、簡単な形でTが表せるらしい。
証明は長いが、結果だけ知っておけばいいかな、という事で結果だけ書いて次のセクションに進む。

定理5.4.1:

![](https://i.imgur.com/akDHuZ4.jpg)

![](https://i.imgur.com/P1zA7D8.jpg)

![](https://i.imgur.com/57bRdbO.jpg)

![](https://i.imgur.com/tUCeWFL.jpg)

![](https://i.imgur.com/fPYAvUx.jpg)

系5.4.2として、5.4.1ならTは連続で可換。

さらに系5.4.4では前の結果と合わせて、シータで連続な関数は可換、も言えるらしい。へー。

なお、5.4.7は可換の式（あとで良く出てくるのでメモ）

## 5.5 T-norm

定義は5.3.1、5.3.2、そして5.4.7(可換)、の3つを満たすI上のassociavive binary operation.

図5.5.1は何を言ってるか全然分からない。とりあえず進む。

定義としては可換というだけなのでrepresentation定理の条件は満たしてない。だが、represen定理の条件を満たしたサブセットの議論が多そうなので、その為の条件を少しメモしておく。

定理 5.5.2 t-normが連続でArchimedeanなのはrepresentation定理の形で表せる時だけ（この時定理の仮定は満たすかな？少し見直したが分からなかった）

定義 5.5.3 $$I^2$$で連続で$$(0, 1]^2$$のいたる所でstrictly increasingなt-normをstrictと呼ぶ。

系 5.5.4 t-normがstrictなのは以下の形で、さらに幾つかの条件がついたもので表せる時だけ（系5.4.3も参考）

![](https://i.imgur.com/pIVPnrr.jpg)

### 5.5.6 additively generatedとmultiplicatively generated

一応軽くメモしておく。

![](https://i.imgur.com/UfcjtOm.jpg)

strictだとfがgのインバースになるので、gだけでadditive generatorと呼ぶんだと。

5.5.8とかTがweakかどうかをgeneratorのsubaditivityで表してて後で使いそうな気もするが、キリが無いので使う時に戻ってこよう。

### 5.5.9 weakerとstronger

任意の定義域のx, y に対し、$$ T_1(x, y) \le T_2(x, y) $$が成り立ち、$$T_1 != T_2$$の時、
$$T_1$$は$$T_2$$よりweakといい、$$T_2$$は$$T_1$$よりstrongと言う。

小さい方をweakと呼ぶのね。

一つのx, yの組に対してだけ成り立っていると、それだけでstronger than or equalとか呼ぶらしい。
マジかよ。

## 5.6のExampleが面白い！

ようやく一章の話とつながった！長かった…

Minはrepresentation定理の形では表せない、ふむ。
Fig. 5.6.1でまた似たような図が出てきたので、真面目に見る。

これはx, y平面で、Mの結果をz軸にとってるのか。なるほど。この形になりそうな気がする。

さっき分からなかったt-normの図5.5.1も同じか？同じっぽいな。どう歪むかは分からんが、単調に上昇していくのだろう。

次はパイ。xyだね。これはstrictなのでgだけで生成出来て、gは-logとなっている。

お次はW。これも5.6.3みたいなgenerator で表現出来る。

ようやく何をやっていたのかが分かってきたなぁ。

## 5.7 t-conormとcomposition law

composition law Lとt-normの違いは定義域のみに見える。LはR+。

# 6 Coupla

そろそろ本題に辿り着いて欲しいのに、まだ下準備が続く…  
まぁ頑張ろう。

さて、なんか6の冒頭は誤植が多くて、…が大文字のデルタになってる。



## sgnとボリューム

一つ一つは簡単だが、少しあとで混ざりそうなので簡単に書いておく。

まずBがn-boxとして、cが頂点とする。
sgnの定義は以下:

![](https://i.imgur.com/Lm14aBS.jpg)

次にH-volumeとHがn-increasingの定義。

まず、HはRのサブセットの$$A_k$$の直積からRへの写像。Aはn-boxとかじゃないらしい。

で、あるBの全頂点がDom Hの時に、Volumeが定義される。別にBの中がDomじゃなくてもいいらしい。へー。

で、H-volumeの定義は以下:

![](https://i.imgur.com/jYsYm0R.jpg)

さらにHがn-increaseとは、Dom Hに頂点が全てある任意のBについて、H-volumeが0以上、との事。

### 具体例の計算

さて、パイスターの場合の答えが載っているので、計算してみよう。

まずパイスターがnondecreasingなのを確認する事から始める。

![](https://i.imgur.com/9GZWbnc.png)

ふむ、nondecreasingだね。
次にこのI2のボリュームを求める。

![](https://i.imgur.com/zV2jxZD.png)

確かに-1となっているので、定義により2-increaseでは無い。

次に-1から1でxyのケースを計算してみよう。
まず、ボリュームは、

![](https://i.imgur.com/VoQFav7.png)

これは正か？eが正の場合と負の場合があるので、そんなに自明でも無いような。

少しいじってみよう。

![](https://i.imgur.com/1sESmdH.png)

お、これはいつも正だな。なるほど。

### n-increaseとはなんぞや？

さて、後者の例で、ちょっとどういう物かのイメージが湧くな。

n-boxのe側の頂点とa側の頂点の差を足したら正になる、eとaが混ざるのは善きに計らって考慮に入れる訳だ。

つまりイメージ的には$$a < e$$の順序を保存する写像みたいな感じだよな。間はよきにはからって考慮に入れるのでここまで単純には書けないが。

### 6.1.4 groundedの定義について

ここで出てくるaはAの最小元であって、boxの端点じゃない事に注意。
つまりHの定義域だな。

### 1次元margins

確率的に重要と思うので、定義を書いておく。
$$A_m$$が最大限$$e_m$$を持つ時、Hはmarginsを持つという。

そして一次元margins $$H_m$$の定義は以下となる。

![](https://i.imgur.com/dyAgElX.jpg)

ようするにm番目以外は全部eなHだね。

eを埋めない部分を複数にする事で、多次元マージンも定義出来る。

## 6.2 Joint DistributionとCoupla

ようやく6章の本題に到達。


### n次元distribution function

以下の条件を満たすHをn次元distribution functionという。

1. $$Dom\ H = R^n $$
2. Hはn-increasingでgrounded
3. $$H(\infty, ..., \infty) = 1$$

joint distributionはHで、2以上のnでn-d.f.となるもの、とある。
joint distributionとn-d.f.の違いはいまいち分からないが、まぁまずはいいだろう。

分布関数がマイナス無限大で0、無限大で1の関数だったので、割と自然な拡張に思う。

一つでも下限なら0、はjoint probabilityの累積分布関数と思えば自然（一つでもゼロな要素がある同時分布はゼロだろう）。

n-increasingは解釈が難しいが、lemma 6.1.8から、特定の変数だけの範囲を広げると、実現確率が増える、という事だよな。

で無限大で1は全部積分すると1になるのに相当するので、わりとわかりやすい定義と思う。

### couplaとsubcoupla

さて、本題っぽいcouplaの話に入るが、まずsubcouplaという物の定義から入る。

以下の条件を満たすC'を、subcouplaと言う。

![](https://i.imgur.com/QHJ1JLh.jpg)

domainがIのサブセットじゃなくてI全体の場合、couplaと呼ぶらしい。

n-d.f.と似ているので、違いを見ておこう。

まずdomainがIのサブセットになっている。Rでは無いのね。

で、marginがidentityになってる。

ふむ。ちょっと何を意味するのか、この時点では良く分からないので、先を読んでいこう。

### 6.2.4 couplaとjoint d.f.の関係

定理6.2.4は強力だな。
任意のjoint distribution functionは、マージナルを引数とするsubcouplaで表せる、と。

感覚的には信じがたいな。マージナライズしてしまうと同時分布の情報は失われてしまう訳で。

ただ、6.2.4を見ると、ようするにsubcoupla自身が同時分布みたいな物なのか。

言っている事は、HのサブセットでHを再現出来る、と言っているんだな。
イメージとしては、IをFのマージンを使ってR全体に射影すれば、DomがIの関数をHに拡張出来る、と言っている。
それはまぁそうか。

### 6.4 copulaのdual

定義はCが2-copulaの時、以下:

![](https://i.imgur.com/TTl2s5G.jpg)

dualはI上のbinary operationで、0がnull、1がidentityで連続でnondecreasing、までは言えるが、2-increase では無いらしい。

M, パイ、Wの結果が6.4.2に書いてあるので、計算してみよう。

![](https://i.imgur.com/JcwTEKP.png)

Lemma 6.3.1によると、Wは2-copulasの中で最小らしい。つまり一番weakという事か。

![](https://i.imgur.com/fh2DLo3.jpg)

ひとしきり納得。なお、Mが2-copulasでstrongestだとか。

## 6.5 CopulasとRandom  Variables

n-d.f.やn-Copulasによる積分がさらっと書いてあるが、さっぱり分からないので、ここに少しメモを書いていく。

まず6.5.1はLebsgue-Stieltjes確率測度の、n次元版の定義なんだな。なんで成り立つか、というよりもこれが定義、と。

比較の為並べて描いておく。

![](https://i.imgur.com/XesOwUA.jpg)

6.5.1は、これがたぶん定義なんだよな。

![](https://i.imgur.com/mUnUYAg.jpg)

さて、まずこいつは測度なのか？
任意のn次元閉区間で定義はされてる。
まぁ開区間でも定義出来るだろう。

厳密な定義はおいとけば、あるboxを分割した時に、メジャーの和になってれば、まぁまぁ納得出来る。

![](https://i.imgur.com/z3B2AJn.jpg)

こんなケースで分割した場合と全体の場合が一致してればいいだろう。

見てみよう。
まず全体。

![](https://i.imgur.com/R4ENf3j.jpg)

次は左と右を個別に求めて足したもの。

![](https://i.imgur.com/0wedQNi.jpg)

間の点のsgnは、片方で正の場合、もう片方では負となる。
ふむ。これなら任意のboxのorで定義されるvolumeは、個々の和になりそうな気がするね。

さて、こうしてあるCやHがあればそれに対応した測度がVolumeで自然に定義出来るのは分かった。

その時、その測度での積分を、元のCやHを使ってdCやdHと表記する訳だ。

6.5.2や6.5.3はVolumeの定義やHの定義から立ちどころに明らか。

### gのHによる積分について

6.5.4では、gをdHで積分してる。
この表記の意味する所を考えよう。

まずHがあると、それに応じた確率測度が考えられるのはさっき見た。
で、その測度でgをルベーグ積分する訳だ。

感覚的にはgの定義域を細かいn-Boxに分割して、このvolumeと真ん中のgの値をかけた物を足し合わせる訳だ。

簡単の為、一次元に戻って考えよう。
Fで定義されるメジャーっていうのは、累積分布関数の差分だから、この区間に入る確率だよな。
すると、これは期待値を計算しているのか。

お、つまりこれ、多次元の奴も期待値になってるんじゃね？
ちょっとここだけじゃ結論出来ないけど、とりあえずそう考えておこう。

追記: dCとかの積分は、リーマン=スティルチェス積分というのがあって、その一般化になってるっぽい。へー、知らなんだ。ただリーマン=スティルチェス積分というのは確かにこれをもっと狭い範囲で定義した物になってるね。

### 確率変数とjoint distribution function

6.5.5は定理とかじゃなく何気なく書かれているが、結構重要な気がする。

確率空間上に確率変数Xがn個定義されてるとする。
この時に、以下で定義されるH

![](https://i.imgur.com/DwBgxTz.jpg)

は、n-d.f.になっていて、これをX1, X2, ..., Xnのjoint distribution functionと呼ぶ。

初めて確率変数との関係が出てきた。
で、あるRnのxベクトルに対し、各確率変数がxベクトルの要素以下になるような標本の集合の測度としてHが定義される。
確率測度Pは最初に確率空間としているから所与。

こうして、確率空間と確率変数が与えられた時に、joint distributionが定義出来るようになった。ちょっと感動である。

さて、これがn-d.f.になってる事を軽く見ておこう。

まず無限大で1なのは、全標本空間となるので良かろう。
n-increasingもオメガの範囲が単調に広がっていくだけなので良かろう。

groundedはどうか？
確率変数の像が有界なのは過程出来るのかな。
で、その時、その最小限より小さいxについてはオメガは空集合となるのでゼロ、つまりgroundedと言えそう。

うむ、n-d.f.にはなりそうだね。
次にマージナルも考えておく。
xがあるk番目の要素以外は無限大の時、それ以外の条件はboundされないので、Hはxkの分布関数となりそう。うむ。我らの知っているjoint distribution になってそうだね。

### 6.5.2のコピュラについて考える

さて、joint d.f.が定義出来たのでn-subcopulaとn-copulaが定義出来る。
これはどういう物か、軽く考えておこう。

まず、Domは$$I^n$$だ。
0から1の範囲で、その各引数をFのQuasi-inverseで戻したjoint d.f.に一致する。
つまり、それぞれのランダム変数が、何割くらいに収まってるかの条件をわたし、その実現確率を返しているんだな。

感覚的にはFからxが再現出来ればcopulasとjoint d.f.はほぼ同じ物になりそう。

ようやくcopulaが何なのか、解釈できた気がする。

### 6章、読み終わった〜〜！

いやぁ、6章はきつかった。しかも結構ちゃんと理解出来た。
読み終わって凄い達成感ある。
大分この分野に詳しくなった感じあるなぁ。
ここまで抽象的に定式化してるの、初めて見たよ。

1970年代とかに作られてる定理が結構出てくる事から、相当新しい分野なのだろうなぁ、という気がする。

次の7章も相当ゴツそうだが、ここを乗り切れば念願の確率分布の距離空間に辿り着く！
一章だけなら頑張れそうな気がする！
頑張るぞ！
