---
title: "深層学習による自然言語処理"
date: 2018-01-29 11:20:15
---

詳解ディープラーニングがいまいちだったので、もうちょっと別の本も読むか、と思って買った本。
さらさらっと読んで見る予定。

<iframe style="width:120px;height:240px;" marginwidth="0" marginheight="0" scrolling="no" frameborder="0" src="https://rcm-fe.amazon-adsystem.com/e/cm?ref=qf_sp_asin_til&t=karino203-22&m=amazon&o=9&p=8&l=as1&IS1=1&detail=1&asins=4061529242&bc1=ffffff&lt1=_top&fc1=333333&lc1=0066c0&bg1=ffffff&f=ifr"> </iframe>

一章、二章はあまり新しい事も無いのでさらっと流す。

3章の言語モデルは、NN以前の機械翻訳の勉強をした時にやったが、良い機会なのでそこそこ真面目に読み直しておく。

3.2.5でperplexityの定義を確認しておく。
このスコアで良く比較してるよね。

3.3は分散表現としてembeddingsの歴史とか解説してるが、これはなかなか詳しい。良く書けているなぁ。

### 3.3.4のnegative samplingの説明が分からん

式を見ても良く分からない。
このへんは[昔](http://jbbs.shitaraba.net/bbs/read.cgi/study/12706/1489317317/)やったんだが、もう忘れた。
4.3.4で詳しくやると言っているのでそちらを見てみる。

すると4.3.3の続きっぽいので4.3.3を軽く眺めると、NCEの話。ああ、分配関数をノイズとのロジスティック回帰で求める、みたいな話か。なんかあったな。

式を眺めただけだがなんとなく思い出したのでnegative samplingを見る。

式自体はnegativeなサンプルとpositiveなサンプルをロジスティック回帰で識別器を作っているように見える。
問題はこの識別器を何に使うかが良く分からんことだな。
3.3.4に戻ってみよう。

3.24式は、ロジスティック回帰のコスト関数になってるな。
で、このファイが学習対象になるんだよな。
ファイは3.18式で、まさにembeddingsを計算している。

つまり、このロジスティック回帰の結果としてembeddingsが得られるのか。

それの確率的な解釈とかは4章でやれば良かろう。今は3.24と3.25を理解しただけで良しとする。

### 3.4.2 系列変換モデルのモデル構造

seq2seqの類のモデルの、一般的な数式の記述。
このレベルだと簡単だよな。

こんなに丁寧に書いてある解説は初めて見た。

もっと短く書けると思うけれど、長い記述を飛ばしながら読む方が、簡潔だけど分からない行間をウンウンうなりながら埋めるよりはずっと楽なので、なかなか好印象。

### 三章を読み終わっての雑感

読み物的な物が挟まってるのと、
記述自体が概要程度に留まってるおかげで、数式が多く見える割にはサラサラ読める。

文章で説明する所と数式で説明する所のバランスが良くて、
数式を細かく見ないでも何を言いたいのか分かる感じで書かれている。
これは書いた人が良く理解している、という事なのかもしれない。

その代わり読んでて何も引っかからないので、自分は多分あんまり分かってないんだろうなぁ、という気もしてくる。
どうしたらいいのかなぁ。実際に実装してみたらいいのか？

結構短い中に必要な事がまとまってるので、一度理解したあとに手元に置いとくのには良い本な気がした。
すぐ読み直せるし。

### 4.1のattentionが良く書けている

さらっと書かれている割には、ハードなattentionの期待値計算の式変形は必要な途中式がちゃんと書かれていて、分かる人には簡単に読み進められるようになっている。
地味に著者は良い仕事をしているなぁ。

一方で、こういう本はあんま売れないかもなぁ、という気もする。
数式をちゃんと理解出来るようにはなっても、とりあえずコピペでなんか動かした気になるコードとかが無いので、
ちゃんと読まないと分かった気になれない。
コードがあると、説明は意味不明でもとりあえず動かす事は出来て、それをやると何か分かった気はする（実際何か分かる事もある）。  
最低限の所をちゃんと分かる為に必要な事を丁寧にやる、って、あんまりウケが良く無いよなぁ。もっと流行りの複雑な奴を、分かってるフリして書く方がウケる傾向にある気がする。

でもそういうのは不健全だよなぁ。
ろくでも無い本とか記事をすぐシェアして、こういう地味だけどしっかりした本とかには全然反応しないのは良くない。

という事でこの本は素晴らしいのでこの分野に興味有る人は読んでみて良いんじゃないかと思う。
これだけで全部ちゃんと分かる、という感じでは無いが、様々な要素技術の関係は理解出来て、必要な所だけは元論文を読んでいく、という基礎にはなってると思う。

### 4.2のmemory  network

4.2.3までは結構真面目に元論文を読んだ事があるので、このくらいの記述で良い復習になった。

4.2.4のDMNは初見なのでこの説明では全然分からないが、そういうのがあるのね、という知識くらいは得られた。
この本の立ち位置はこういう感じだよね。
